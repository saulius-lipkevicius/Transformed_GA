{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TuLR0BMJhIub"
   },
   "source": [
    "# ALBERT for aptamer-pair classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.onnx\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ruamel.yaml\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
    "import transformers\n",
    "import logging\n",
    "transformers.logging.get_verbosity = lambda: logging.NOTSET\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "config_name = 'config.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpKx43Iq6znw"
   },
   "source": [
    "## Load your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_name, 'r') as stream:\n",
    "    try:\n",
    "        yaml = ruamel.yaml.YAML()\n",
    "        config = yaml.load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train_data = config['Datasets']['train']\n",
    "path_to_val_data = config['Datasets']['val']\n",
    "path_to_test_data = config['Datasets']['test']\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(path_to_train_data)\n",
    "df_val = pd.read_csv(path_to_val_data)\n",
    "df_test = pd.read_csv(path_to_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nNs2FWNJSLSq",
    "outputId": "62dc686d-df2e-4c6d-97f1-b17f81d238ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(899400, 3) (112425, 3) (112425, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_val.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "irj7itV0UCF_",
    "outputId": "a648d128-a509-4cf7-8b27-7474d83a50dd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence1</th>\n",
       "      <th>Sequence2</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GCGGTAACCGGTGCT</td>\n",
       "      <td>GGAGAACAACAACTT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATCAGATACTATGCG</td>\n",
       "      <td>TACAGAACTAGCAGG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGAGTGCCCTGTCCC</td>\n",
       "      <td>ATCTGCTAACCAGTC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATTCCCAAGCTGCGA</td>\n",
       "      <td>GTACCCGGGATGTTA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GCGAGCTCATGCACA</td>\n",
       "      <td>GGGCGCCATAGTTCG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sequence1        Sequence2  Label\n",
       "0  GCGGTAACCGGTGCT  GGAGAACAACAACTT      0\n",
       "1  ATCAGATACTATGCG  TACAGAACTAGCAGG      0\n",
       "2  AGAGTGCCCTGTCCC  ATCTGCTAACCAGTC      0\n",
       "3  ATTCCCAAGCTGCGA  GTACCCGGGATGTTA      0\n",
       "4  GCGAGCTCATGCACA  GGGCGCCATAGTTCG      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWJfh6DV7CB5"
   },
   "source": [
    "## Classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Tc1GQh7yEm4C"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, maxlen, with_labels=True, bert_model='albert-base-v2'):\n",
    "        self.data = data  # pandas dataframe\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(bert_model, return_dict=False)  \n",
    "        self.maxlen = maxlen\n",
    "        self.with_labels = with_labels \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sent1 = str(self.data.loc[index, 'Sequence1'])\n",
    "        sent2 = str(self.data.loc[index, 'Sequence2'])\n",
    "\n",
    "        # Tokenize the pair of sentences to get token ids, attention masks and token type ids\n",
    "        encoded_pair = self.tokenizer(sent1, sent2, \n",
    "                                      padding='max_length',  # Pad to max_length\n",
    "                                      truncation=True,  # Truncate to max_length\n",
    "                                      max_length=self.maxlen,  \n",
    "                                      return_tensors='pt')  # Return torch.Tensor objects\n",
    "        \n",
    "        token_ids = encoded_pair['input_ids'].squeeze(0)  # tensor of token ids\n",
    "        attn_masks = encoded_pair['attention_mask'].squeeze(0)  # binary tensor with \"0\" for padded values and \"1\" for the other values\n",
    "        token_type_ids = encoded_pair['token_type_ids'].squeeze(0)  # binary tensor with \"0\" for the 1st sentence tokens & \"1\" for the 2nd sentence tokens\n",
    "\n",
    "        if self.with_labels:  # True if the dataset has labels\n",
    "            label = self.data.loc[index, 'Label']\n",
    "            return token_ids, attn_masks, token_type_ids, label  \n",
    "        else:\n",
    "            return token_ids, attn_masks, token_type_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, bert_model=\"albert-base-v2\", freeze_bert=False):\n",
    "        super(Model, self).__init__()\n",
    "        self.bert_layer = AutoModel.from_pretrained(bert_model, return_dict=False)\n",
    "\n",
    "        #  Fix the hidden-state size of the encoder outputs\n",
    "        #  More information can be found https://huggingface.co/transformers/pretrained_models.html\n",
    "        hidden_size = config['Model']['hidden_size']\n",
    "\n",
    "        # Freeze bert layers and only train the classification layer weights\n",
    "        if freeze_bert:\n",
    "            for p in self.bert_layer.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        # Classification layer\n",
    "        self.cls_layer = nn.Linear(hidden_size, config['Model']['number_labels'])\n",
    "        self.dropout = nn.Dropout(p=config['Model']['dropout_rate'])\n",
    "\n",
    "    @autocast()  # run in mixed precision\n",
    "    def forward(self, input_ids, attn_masks, token_type_ids):\n",
    "        '''\n",
    "        Inputs:\n",
    "            -input_ids : Tensor  containing token ids\n",
    "            -attn_masks : Tensor containing attention masks to be used to focus on non-padded values\n",
    "            -token_type_ids : Tensor containing token type ids to be used to identify sentence1 and sentence2\n",
    "        '''\n",
    "\n",
    "        # Feeding the inputs to the BERT-based model to obtain contextualized representations\n",
    "        cont_reps, pooler_output = self.bert_layer(input_ids, attn_masks, token_type_ids)\n",
    "\n",
    "        # Feeding to the classifier layer the last layer hidden-state of the [CLS] token further processed by a\n",
    "        # Linear Layer and a Tanh activation. The Linear layer weights were trained from the sentence order prediction (ALBERT) or next sentence prediction (BERT)\n",
    "        # objective during pre-training.\n",
    "        logits = self.cls_layer(self.dropout(pooler_output))\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5SrSNNYTjwe8"
   },
   "outputs": [],
   "source": [
    "#seed to make results reproducible\n",
    "def set_seed(seed):\n",
    "    \"\"\" Set all seeds to make results reproducible \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "\n",
    "def evaluate_loss(net, device, criterion, dataloader):\n",
    "    net.eval()\n",
    "\n",
    "    mean_loss = 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for it, (seq, attn_masks, token_type_ids, labels) in enumerate(tqdm(dataloader)):\n",
    "            seq, attn_masks, token_type_ids, labels = \\\n",
    "                seq.to(device), attn_masks.to(device), token_type_ids.to(device), labels.to(device)\n",
    "            logits = net(seq, attn_masks, token_type_ids)\n",
    "            mean_loss += criterion(logits.squeeze(-1), labels.float()).item()\n",
    "            count += 1\n",
    "\n",
    "    return mean_loss / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "I-o6KyaFkU5u"
   },
   "outputs": [],
   "source": [
    "def train_bert(net, criterion, opti, lr, lr_scheduler, train_loader, val_loader, epochs, iters_to_accumulate):\n",
    "\n",
    "    best_loss = np.Inf\n",
    "    nb_iterations = len(train_loader)\n",
    "    print_every = nb_iterations // config['Random']['print_every']  # print the training loss 5 times per epoch\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    iters = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for ep in range(epochs):\n",
    "\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        for it, (seq, attn_masks, token_type_ids, labels) in enumerate(tqdm(train_loader)):\n",
    "\n",
    "            # Converting to cuda tensors\n",
    "            seq, attn_masks, token_type_ids, labels = \\\n",
    "                seq.to(device), attn_masks.to(device), token_type_ids.to(device), labels.to(device)\n",
    "    \n",
    "            # Enables autocasting for the forward pass (model + loss)\n",
    "            with autocast():\n",
    "                # Obtaining the logits from the model\n",
    "                logits = net(seq, attn_masks, token_type_ids)\n",
    "\n",
    "                # Computing loss\n",
    "                loss = criterion(logits.squeeze(-1), labels.float())\n",
    "                loss = loss / iters_to_accumulate  # Normalize the loss because it is averaged\n",
    "\n",
    "            # Backpropagating the gradients\n",
    "            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (it + 1) % iters_to_accumulate == 0:\n",
    "                # Optimization step\n",
    "                # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
    "                # If these gradients do not contain infs or NaNs, opti.step() is then called,\n",
    "                # otherwise, opti.step() is skipped.\n",
    "                scaler.step(opti)\n",
    "                # Updates the scale for next iteration.\n",
    "                scaler.update()\n",
    "                # Adjust the learning rate based on the number of iterations.\n",
    "                lr_scheduler.step()\n",
    "                # Clear gradients\n",
    "                opti.zero_grad()\n",
    "\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if (it + 1) % print_every == 0:  # Print training loss information\n",
    "                print()\n",
    "                print(\"Iteration {}/{} of epoch {} complete. Loss : {} \"\n",
    "                      .format(it+1, nb_iterations, ep+1, running_loss / print_every))\n",
    "                \n",
    "                train_losses.append(running_loss)\n",
    "                running_loss = 0.0\n",
    "\n",
    "\n",
    "        val_loss = evaluate_loss(net, device, criterion, val_loader)  # Compute validation loss\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        print()\n",
    "        print(\"Epoch {} complete! Validation Loss : {}\".format(ep+1, val_loss))\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            print(\"Best validation loss improved from {} to {}\".format(best_loss, val_loss))\n",
    "            print()\n",
    "            net_copy = copy.deepcopy(net)  # save a copy of the model\n",
    "            best_loss = val_loss\n",
    "        \n",
    "        \n",
    "    \n",
    "    # Saving the model\n",
    "    path_to_model='model/{}_{}_{}.pt'.format(bert_model, lr, round(best_loss, 4))\n",
    "    path_to_model_evaluation = './datasets/model_validation/{}_{}_{}.csv'.format(bert_model, lr, round(best_loss, 4))\n",
    "    path_to_model_test = './datasets/model_validation/pred-{}_{}_{}.csv'.format(bert_model, lr, round(best_loss, 4))\n",
    "    \n",
    "    #  Following val/test losses to graph it later\n",
    "    model_training = './datasets/model_validation/{}_{}_{}_training.csv'.format(bert_model, lr, round(best_loss, 4))\n",
    "    losses = pd.DataFrame({'Train loss': train_losses, 'Val loss': val_losses})\n",
    "    losses.to_csv(model_training)\n",
    "    \n",
    "    config['Random']['path_to_model'] = path_to_model\n",
    "    config['Random']['path_to_model_evaluation'] = path_to_model_evaluation\n",
    "    config['Random']['path_to_model_test'] = path_to_model_test\n",
    "\n",
    "    torch.save(net_copy.state_dict(), path_to_model)\n",
    "    print(\"The model has been saved in {}\".format(path_to_model))\n",
    "\n",
    "    del loss\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFy9kQ2-SvQ2"
   },
   "source": [
    "## Hyperparameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = config['Model']['bert_model']  # any of previously defined BERT alternatives :'albert-base-v2', 'albert-large-v2', 'albert-xlarge-v2', 'albert-xxlarge-v2' and others\n",
    "freeze_bert = config['Model']['freeze_bert']  # if True, freeze the encoder weights and only update the classification layer weights\n",
    "maxlen = config['Model']['max_len']        # maximum length of the tokenized input sentence pair : if greater than \"maxlen\", the input is truncated and else if smaller, the input is padded\n",
    "bs = config['Model']['batch_size']                # batch size\n",
    "iters_to_accumulate = config['Model']['iters_to_accumulate']  # the gradient accumulation adds gradients over an effective batch of size : bs * iters_to_accumulate. If set to \"1\", you get the usual batch size\n",
    "lr = config['Model']['learning_rate']                # learning rate\n",
    "epochs = config['Model']['epochs']             # number of training epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_abThXlSr6n",
    "tags": []
   },
   "source": [
    "nb_iterations = len(train_loader)## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training data...\n",
      "Reading validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.dense.weight', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.decoder.bias', 'predictions.dense.bias', 'predictions.bias', 'predictions.decoder.weight']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#  Set all seeds to make reproducible results\n",
    "set_seed(2)\n",
    " \n",
    "# Creating instances of training and validation set\n",
    "print(\"Reading training data...\")\n",
    "train_set = CustomDataset(df_train, maxlen, bert_model)\n",
    "print(\"Reading validation data...\")\n",
    "val_set = CustomDataset(df_val, maxlen, bert_model)\n",
    "# Creating instances of training and validation dataloaders\n",
    "train_loader = DataLoader(train_set, batch_size=bs, num_workers=2)\n",
    "val_loader = DataLoader(val_set, batch_size=bs, num_workers=2)\n",
    " \n",
    " \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = Model(bert_model, freeze_bert=freeze_bert)\n",
    "\n",
    "if torch.cuda.device_count() > 1:  # if multiple GPUs\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    net = nn.DataParallel(net)\n",
    "\n",
    "net.to(device)\n",
    "   \n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "opti = AdamW(net.parameters(), lr=lr, weight_decay=1e-2)\n",
    "num_warmup_steps = config['Model']['num_warmup_steps'] # The number of steps for the warmup phase.\n",
    "num_training_steps = epochs * len(train_loader)  # The total number of training steps\n",
    "t_total = (len(train_loader) // iters_to_accumulate) * epochs  # Necessary to take into account Gradient accumulation\n",
    "lr_scheduler = get_linear_schedule_with_warmup(optimizer=opti, num_warmup_steps=num_warmup_steps, num_training_steps=t_total)\n",
    "                         \n",
    "#train_bert(net, criterion, opti, lr, lr_scheduler, train_loader, val_loader, epochs, iters_to_accumulate)\n",
    "\n",
    "with open('config.yaml', 'w') as conf:\n",
    "    yaml.dump(config, conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot training losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = pd.read_csv('./datasets/model_validation/albert-base-v2_5e-05_0.1372_training.csv')\n",
    "plt.plot(losses[['Val loss','Train loss']][0:45])\n",
    "plt.savefig(\"val-train.png\") # save as png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "qZXAwn0zqTuc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!kill -9 -1 #in case you have to kill the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDBtVu7JSbUK"
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "m3r8_npVf30D"
   },
   "outputs": [],
   "source": [
    "def get_probs_from_logits(logits):\n",
    "    \"\"\"\n",
    "    Converts a tensor of logits into an array of probabilities by applying the sigmoid function\n",
    "    \"\"\"\n",
    "    probs = torch.sigmoid(logits.unsqueeze(-1))\n",
    "    return probs.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "def test_prediction(net, device, aptamerDataFrame, dataloader, with_labels, result_path=config['Random']['path_to_model_test']):\n",
    "    \"\"\"\n",
    "    Predict the probabilities on a dataset with or without labels and print the result in a file\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    probs_all = []\n",
    "    nb_iterations = len(dataloader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if with_labels:\n",
    "            for it, (seq, attn_masks, token_type_ids, label) in enumerate(tqdm(dataloader)):\n",
    "                seq, attn_masks, token_type_ids = seq.to(device), attn_masks.to(device), token_type_ids.to(device)\n",
    "                logits = net(seq, attn_masks, token_type_ids)\n",
    "                probs = get_probs_from_logits(logits.squeeze(-1)).squeeze(-1)\n",
    "                probs_all += probs.tolist()\n",
    "                \n",
    "        else:\n",
    "            for it, (seq, attn_masks, token_type_ids, token_ids) in enumerate(tqdm(dataloader)):\n",
    "                seq, attn_masks, token_type_ids = seq.to(device), attn_masks.to(device), token_type_ids.to(device)\n",
    "                logits = net(seq, attn_masks, token_type_ids)\n",
    "                probs = get_probs_from_logits(logits.squeeze(-1)).squeeze(-1)\n",
    "                probs_all += probs.tolist()\n",
    "            \n",
    "    y_hat = [round(x) for x in probs_all]     \n",
    "    df2 = pd.DataFrame({'y_hat': y_hat, 'prob': probs_all})\n",
    "    df = pd.concat([aptamerDataFrame, df2], axis=1)\n",
    "    df.to_csv(result_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.dense.weight', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.decoder.bias', 'predictions.dense.bias', 'predictions.bias', 'predictions.decoder.weight']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading the weights of the model...\n",
      "Predicting on test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1757/1757 [01:33<00:00, 18.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions are available in : ./datasets/model_validation/pred-albert-base-v2_5e-05_0.1075.csv\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Reading test data...\")\n",
    "test_set = CustomDataset(df_test, maxlen, bert_model)\n",
    "test_loader = DataLoader(test_set, batch_size=bs, num_workers=4)\n",
    "\n",
    "model = Model(bert_model)\n",
    "if torch.cuda.device_count() > 1:  # if multiple GPUs\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "print()\n",
    "print(\"Loading the weights of the model...\")\n",
    "model.load_state_dict(torch.load(config['Random']['path_to_model']))\n",
    "model.to(device)\n",
    "\n",
    "print(\"Predicting on test data...\")\n",
    "test_prediction(net=model\n",
    "                , device=device\n",
    "                , dataloader=test_loader\n",
    "                , aptamerDataFrame=df_test\n",
    "                , with_labels = True)\n",
    "\n",
    "print()\n",
    "print(\"Predictions are available in : {}\".format(config['Random']['path_to_model_test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.972497220369135\n",
      "precision:  0.9952591597140564\n",
      "recall:  0.9494667117750752\n",
      "f1:  0.9718237985018864\n",
      "roc_auc:  0.9774729030292202\n",
      "matrix: \n",
      " [[56010   254]\n",
      " [ 2838 53323]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(config['Random']['path_to_model_test'])\n",
    "\n",
    "accuracy = accuracy_score(df['Label'], df['y_hat'])\n",
    "precision = precision_score(df['Label'], df['y_hat'])\n",
    "recall = recall_score(df['Label'], df['y_hat'])\n",
    "f1 = f1_score(df['Label'], df['y_hat'])\n",
    "roc_auc = roc_auc_score(df['Label'], df['prob'])\n",
    "matrix = confusion_matrix(df['Label'], df['y_hat'])\n",
    "\n",
    "print('accuracy: ', accuracy)\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)\n",
    "print('f1: ', f1)\n",
    "print('roc_auc: ', roc_auc)\n",
    "print('matrix: \\n', matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA31ElEQVR4nO3deXgUVdbA4d8hAQIKuICOyr4nBESMOIDsu4LrICoy6gQQEGREZUAUFRkGEARRdkQQEAYXFJUR9w/FFWWRRRSRHWWRRWTLcr4/qhKakHQKkkqn0+d9nn66q7q6+lQH7qm699a9oqoYY4yJXIVCHYAxxpjQskRgjDERzhKBMcZEOEsExhgT4SwRGGNMhIsOdQBnqnTp0lqxYsVQh2GMMWHl22+/3auqZTJ7L+wSQcWKFVm+fHmowzDGmLAiIluyes+qhowxJsJZIjDGmAhnicAYYyKcJQJjjIlwlgiMMSbC+ZYIRGSGiOwWkTVZvC8iMl5ENorIahGp51csxhhjsubnFcFMoF2Q99sD1dxHD2CSj7EYY4zJgm/3EajqUhGpGGSTG4CX1BkH+0sROU9ELlHVXX7FZIwxoaCqnEhJ5XhyKieSA59TOJ6U6ryX5Cyf9n5yKof+OMzv+/bSqVk9Li93Xq7HF8obyi4DtgUsb3fXnZYIRKQHzlUD5cuXz5PgjDHhL60APnFaAeyuS3EK4uNuQewUyCnpnzmenLY+kwI7/fWphXb65zKsO1tHt6zi93efo1DRc6j++vsFLhF4pqpTgakACQkJNpOOMfmYqpKcqumF74mUgMI0Y0Gc9jpDQZt29pzxDPlEZusyKcSPB7yfG6IKCUWjC1E0uhBFogtRNDoq4LXzfF7xIqe+X7gQRaIKUbTwye0DP1M0OirT12nPx478wX8eH8yc+S9SpWpVpk+bRrOGlXLleDIKZSLYAZQLWC7rrjPGnKHU1FOrHk6e0aacLJCTTz3zPbk+JZPPZdxXyimFceB2J59PFsK5NfFhZgVnWuGa9lwiJjq98A0sTE8psDN8pkhUZttm/T3RUXnbwTIlJYXaTeuzYcMGBgwYwBNPPEGxYsV8+75QJoJFQB8RmQ9cDRy09gETTlSVpBQ99Uz0lLPa06sdMjujPX0586qGLAv4lFSSUnKn5BUhveAskuEsNrBwTCt8i0RHnVrIZjhLTttPVoVukaioDAX0yQK8cJQgIrlyXOFi3759XHDBBURFRfHvf/+bcuXKkZCQ4Pv3+pYIRGQe0AwoLSLbgceBwgCqOhlYDFwLbASOAPf4FYspWFTVrU7IpEogk4I4vS43k/rf7ArijOvTznzTvj83znwLCadVJTiFalR6wVkiJvqUwjXwvdPOkgPOhk8WxqcW0BkL4bT3owtFXuGbH6gqc+fOpV+/fowYMYLu3btz00035dn3+9lr6PZs3lfgPr++3+S+tAI44xlr5r0dsqj3TUrJ5Az51KqH7AroEym5U+9bOEqyrG5IK2yLF48+rWAtGnhGm8l7mS9nXhccimoHk79s27aNnj17snjxYv7617/SqFGjPI8hLBqLjSM5oBEsrdvZaYVywPrAgtQpsFNO/XxAr4hTlzN8Lhd6PgTKrmCMKVyIkjHRZ1y4ZrdtxjrjQoXszNeE1rx587j33ntJSUlh3Lhx9OnTh6ioqDyPwxLBGUrrEZGxF8OxpFSOuQXtsaSUU18HFMKnvZd06uczbhv4nJKa83qI9MKzcNQpBWnaWXCpYoUpWqLoKeszFqKZfj7bM+STBb1VPRjjOP/887n66quZOnUqlSr50yPIC9Hcat7PIwkJCZrTiWkOHUtizfaDrNt1iN8OHePg0ST+PJ7CkRPJHE1K4cgJ53HMPTNOTlWSUk5WS+TkJxOBmOgoYtwuZTGFCxGTVqgWjkp/HVM4iphop5oixi2QY06pR446tRAunEnVRYbCOhIb34zJT5KTkxk7diwnTpxg8ODBgHNymRf/L0XkW1XNtOU5oq4IklNSGfG/H5j1xeb0XhYxhQtxXrEinFM0iuJFoilWJIoLzilC2fOdQtmpwxWiCwWvFz6lAA8o5NPOqp2C3QpjYyLVqlWrSExM5Ntvv+XWW29NTwD5oTyIqEQw9O11vPTFFjpdWZYOl19K/KUlueCcIvniD2GMKZiOHz/OsGHDGDFiBBdccAGvvPIKt9xyS74qdyImERw4coI5X26h618r8NSN8aEOxxgTIX766SdGjhzJHXfcwTPPPMOFF14Y6pBOEzGJYN3OQ6QqtK31l1CHYowp4A4fPsybb75Jly5diI+P54cffqBy5cqhDitLEdOBec/h4wD8pVRMiCMxxhRk77//PrVr16Zr166sX78eIF8nAYigRJDGuo4bY/ywf/9+EhMTadOmDUWKFOH//u//iI2NDXVYnkRM1ZAxxvglJSWFRo0a8eOPPzJo0CCGDBlCTEz41D5YIjDGmLO0d+/e9EHihg8fTvny5alXL/xm3Y24qiFjjMkpVeWll16ievXqTJ8+HYAbb7wxLJMAnEEiEJFzRCTvB8Ewxph8ZMuWLbRv35677rqL2NhYmjRpEuqQcizLRCAihUTkDhF5R0R2Az8Au0RknYg8LSJV8y7MnAuzkTSMMfnQnDlziI+P57PPPuO5557j008/pWbNmqEOK8eCtRF8DHwADALWqGoqgIhcADQHRorIQlWd43+YuSc/3c1njAkvZcqUoVGjRkyZMoUKFSqEOpxcEywRtFLVpIwrVfV34DXgNREp7FtkxhgTYklJSYwZM4akpCQee+wx2rZtS5s2bQrcCWWWVUNpSUBExohIrWDbGGNMQbNixQquvvpqBg0axLp160gbqbmgJQHw1li8HpgqIl+JSE8RKeV3UMYYEyrHjh3jkUce4aqrrmLnzp289tprzJs3r0AmgDTZJgJVna6qjYC/AxWB1SLysog09zs4Y4zJaxs3bmT06NH8/e9/Z/369dx8882hDsl3nrqPut1Ga7qPvcAqoL+IzPcxNmOMyROHDx9m9uzZAMTHx7NhwwZmzJjB+eefH+LI8ka2iUBExuJ0Hb0WGK6qV6rqSFXtCFzhd4C5RbH+o8aY0y1ZsoRatWpx1113pQ8SF8ppI0PByxXBaqCuqt6rql9neK++DzH5quDW8hljzsS+ffu46667aNeuHcWLF+fTTz8Nm0HicpuXRHCnqv4ZuEJEPgRQ1YO+RGWMMT5KGyRu7ty5DB48mBUrVtCoUaNQhxUyWd5HICIxQHGgtIicz8mT6ZLAZXkQmzHG5Ko9e/Zw4YUXEhUVxciRI6lQoQJ169YNdVghF+yK4F7gW5wG4u/c198CbwLP+x+aMcbkDlXlxRdfpHr16kybNg2AG264wZKAK8srAlV9FnhWRPqq6nN5GJMxxuSazZs306NHD95//30aN25M8+bW8z2jYFVDLVT1I2CHiJzWkVZVX/c1MmOMyaHZs2fTq1cvRISJEydy7733UqiQjb6fUbCxhpoCHwEdM3lPgbBKBDb6qDGR5+KLL6ZJkyZMnjyZ8uXLhzqcfCtY1dDj7stuqpqSR/H4rgDfJW5MxEtKSmLUqFGkpKQwZMgQ2rRpQ5s2bUIdVr7n5RrpFxGZKiItpSAPtmGMCWvfffcdV111FY8++igbNmxIHyTOZM9LIqiJMy/BfThJ4XkRucbfsIwxxpujR48ycOBA6tevz2+//cbChQuZO3dugR4kLrd5GXTuiKouUNWbcYaUKAn8n5edi0g7EdkgIhtFZGAm75cXkY9FZIWIrBaRa8/4CIwxEW3Tpk0888wz3H333axbt44bb7wx1CGFHa+DzjUVkYk49xHEALd6+EwUMAFoD8QBt4tIXIbNHgUWqOoVwG3AxDOI3RgToQ4dOsTMmTMBqFWrFj/99BPTp0+PmEHicpuXQec2A/8EPgVqq+qtqvqah33XBzaq6iZVPQHMB27IsI3iXGEAlAJ2eoz7jFl1oTEFw+LFi4mPjycxMTF9kLiCNG1kKHi5Iqijqjep6ryMYw5l4zJgW8Dydk4fmuIJ4E4R2Q4sBvpmtiMR6SEiy0Vk+Z49e84ghEz2ZcPOGROW9u7dS9euXbnuuusoUaIEy5Yti9hB4nJbsBvKBqjqKODfInLa+bSq3p8L3387MFNVx4hIA2C2iMSramqG75oKTAVISEiwc3tjIkzaIHGbNm1iyJAhPPLIIxQtWjTUYRUYwW4oW+8+Lz/Lfe8AygUsl3XXBUoE2gGo6hfuQHelgd1n+Z3GmALkt99+o0yZMkRFRTF69GgqVKhAnTp1Qh1WgRNs8vq33JdHVHVW4AM44mHf3wDVRKSSiBTBaQxelGGbrUBLABGJxWmIzlndjzEm7KkqL7zwAjVq1GDq1KkAdOzY0ZKAT7y0EQzyuO4UqpoM9AGW4FxdLFDVtSIyVESudzd7EOguIquAecDdaneBGBPRNm3aRKtWrejWrRt169alVatWoQ6pwAvWRtAeZ3rKy0RkfMBbJYFkLztX1cU4jcCB64YEvF4HRO5sEMaYU8yaNYvevXsTFRXF5MmT6d69uw0SlweCtRHsxGkfuB7n/oE0fwAP+BmUH+wyw5j879JLL6VFixZMmjSJsmXLhjqciBFs0LlVwCoRmetW8xQIdte5MfnHiRMnGDFiBKmpqTzxxBO0bt2a1q1bhzqsiBOsamiBqt4KrMjQfVQAVVVrtTHGnLVvvvmGf/zjH6xZs4auXbuiqjY+UIgEqxrq5z53yItAjDGR4ciRIwwZMoSxY8dyySWXsGjRIjp2zGzaE5NXgnUf3eW+3AtsU9UtQFHgcnwcCsIYU7D98ssvPPfcc3Tv3p21a9daEsgHvDTHLwViROQy4D2gKzDTz6CMMQXLwYMHefHFFwFnkLiNGzcyefJkSpUqFeLIDHhLBKKqR4CbgYmq2gmo5W9Yuc9uTzAmNN555x1q1apFt27d+OGHHwAoV65cNp8yeclTInDHAeoCvOOui/IvJGNMQbBnzx66dOlChw4dOP/88/niiy+oWbNmqMMymQjWWJymH86dxAvdO4MrAx/7G5YxJpylpKRwzTXX8Msvv/Dkk08ycOBAihQpEuqwTBayTQSquhSnnSBteROQGyOPGmMKmF9//ZWLLrqIqKgoxowZQ8WKFYmPjw91WCYbXiamqe5OXv+eiHyU9siL4Iwx4SE1NZUpU6ZQvXp1pkyZAkCHDh0sCYQJL1VDrwCTgelAir/hGGPCzcaNG+nevTuffPIJLVq0oG3btqEOyZwhL4kgWVUn+R6JMSbsvPjii/Tu3ZsiRYowbdo0EhMT7e7gMOQlEbwlIr2BhcDxtJWq+rtvUfnAOo8ak/vKly9P27ZtmTBhApddlnEmWhMuvCSCu9znhwPWKVA598Pxn52sGHP2jh8/zn/+8x9SU1MZOnQoLVu2pGXLlqEOy+SQl15DlfIiEGNM/vbVV1+RmJjI2rVrueuuu2yQuALES6+h4iLyqIhMdZeriYgNRGdMhPjzzz/p378/DRo04ODBg7z99tvMnDnTkkAB4uXO4heBE0BDd3kHMMy3iIwx+cqWLVuYOHEiPXv2ZO3atVx33XWhDsnkMi+JoIqqjgKSANxxh+xUwJgC7MCBA0yfPh2AuLg4Nm7cyMSJEylZsmSIIzN+8JIITohIMdyONyJShYDeQ8aYguXNN98kLi6Onj17pg8SZ9NGFmxeEsHjwLtAORGZC3wIDPA1Kj9Y/1Fjgtq9eze33XYbN954I2XKlOHLL7+0QeIihJdeQ++LyHfAX3GqhPqp6l7fI/OJNXAZc7qUlBQaNWrE1q1bGTZsGAMGDKBw4cKhDsvkkWBzFlcADqjqQVXdJyJHgBuB6iLyvKqeyKsgjTH+2LlzJ3/5y1+Iiori2WefpWLFisTFxYU6LJPHglUNLQDOARCRujhjDm3Fmapyou+RGWN8k5qayqRJk6hZsyaTJ08G4Nprr7UkEKGCVQ0VU9W0uYnvBGao6hgRKQSs9D0yY4wvfvzxR7p3787SpUtp1aoV7du3D3VIJsSCXREEVqa3wGkkRlVTfY3IGOObF154gcsvv5zVq1czY8YM3nvvPSpVssEDIl2wK4KPRGQBsAs4H/gIQEQuwbnBLKyodRsyhooVK9K+fXsmTJjAJZdcEupwTD4RLBH8E+gMXAJco6pJ7vq/AIN9jss31mfIRJLjx4/z1FNPATBs2DAbJM5kKmj3UVWdn8m6FWmvRURU1U61jcmHPv/8cxITE/nhhx/4xz/+YYPEmSwFayP4WET6ikj5wJUiUkREWojILE4OUW2MyScOHz5Mv379uOaaazhy5AjvvvsuL7zwgiUBk6VgiaAdztSU80Rkp4isE5FNwE/A7cA4VZ0ZbOci0k5ENojIRhEZmMU2t7r7XisiL5/lcRhjXFu3bmXKlCncd999rFmzxqaONNnKsmpIVY/h3C8wUUQKA6WBo6p6wMuORSQKmAC0BrYD34jIIlVdF7BNNWAQ0EhV94vIRWd9JMZEsP379/PKK6/Qo0cP4uLi2LRpE5deemmowzJhwstYQ6hqkqru8poEXPWBjaq6yb0LeT5wQ4ZtugMTVHW/+z27z2D/xhhg4cKFxMXF0bt3bzZs2ABgScCcEU+J4CxdBmwLWN7urgtUHWfIimUi8qWItMtsRyLSQ0SWi8jyPXv2nFUw1qRtCppff/2VTp06cfPNN/OXv/yFr7/+mho1aoQ6LBOGvMxZ7Pf3VwOaAWWBpSJSO+OVh6pOBaYCJCQk5KhIt/YyUxCkpKTQuHFjtm3bxvDhw3nooYdskDhz1oImAree/wNVbX4W+94BlAtYLuuuC7Qd+Mq9R+EXEfkRJzF8cxbfZ0yBt337di699FKioqIYP348lSpVsqGiTY4FrRpS1RQgVURKncW+vwGqiUglESkC3AYsyrDNGzhXA4hIaZyqok1n8V3GFGipqak899xz1KxZk0mTJgHQvn17SwImV3ipGjoMfC8i7wN/pq1U1fuDfUhVk0WkD7AEiMIZtG6tiAwFlqvqIve9NiKyDqer6sOquu8sj8WYAumHH36gW7duLFu2jLZt29KhQ4dQh2QKGC+J4HX3ccZUdTGwOMO6IQGvFejvPowxGUyfPp0+ffpQvHhxZs2aRdeuXe3GMJPrvMxQNsut2qnurtoQMO6QMcZHVapUoWPHjjz//PNcfPHFoQ7HFFDZJgIRaQbMAjbjjNlWTkTuUtWlvkaWy6z3qAkHx44dY+jQoQAMHz6c5s2b07z52fTVMMY7L/cRjAHaqGpTVW0CtAXG+huWf8TGHzX51LJly6hbty7/+c9/2LNnDzaeo8krXhJBYVXdkLagqj8C1mHZmFzyxx9/0LdvXxo3bszx48dZsmQJ06ZNs7YAk2e8JILlIjJdRJq5j2nAcr8DMyZSbN++nenTp9O3b1++//572rRpE+qQTITx0muoF3AfkNZd9FNs8npjcmTfvn0sWLCAXr16ERsby6ZNm2zGMBMyXnoNHQeecR/GmBxQVV577TXuu+8+fv/9d1q0aEGNGjUsCZiQ8nPQuXzF2t1MqO3atYtbbrmFTp06Ua5cOZYvX26DxJl8IdSDzuU5a38zoZA2SNyOHTsYNWoUDzzwANHREfffz+RTnv8likhxVT3iZzDGFDTbtm3jsssuIyoqigkTJlCpUiWqV6+e/QeNyUPZVg2JSEN3LKAf3OXLRcQai40JIiUlhfHjx58ySFzbtm0tCZh8yUsbwVicm8j2AajqKqCJn0EZE87Wr19P48aN6devH02bNqVjx46hDsmYoLxOVbktw6oUH2IxJuxNnTqVunXr8uOPPzJ79mzeeecdypcvH+qwjAnKSxvBNhFpCKg7iX0/YL2/YRkTnqpVq8ZNN93E+PHjueiii0IdjjGeeEkEPYFnceYb3gG8B/T2Myg/qA07Z3xw9OhRnnjiCUSEESNG2CBxJix5qRqqoapdVPViVb1IVe8EYv0OzC/We9TklqVLl3L55ZczatQoDh48aIPEmbDlJRE853GdMRHh0KFD9O7dm6ZNm5KSksKHH37IpEmTbJA4E7ayrBoSkQZAQ6CMiATOIFYSZ+pJYyLSzp07mTlzJv3792fo0KGcc845oQ7JmBwJ1kZQBDjX3aZEwPpDwN/8DMqY/Gbv3r0sWLCA3r17U7NmTX755RebMcwUGFkmAlX9P+D/RGSmqm7Jw5iMyTdUlQULFtC3b18OHDhAq1atqF69uiUBU6B46TV0RESeBmoBMWkrVbWFb1H5wNrxzJnauXMnvXr1YtGiRSQkJPDhhx/ancGmQPLSWDwXZ3iJSsCTOHMXf+NjTP6y9jzjQUpKCk2aNOG9995j9OjRfPHFF9SuXTvUYRnjCy9XBBeq6gsi0i+guih8E4ExQWzZsoWyZcsSFRXFxIkTqVy5MlWrVg11WMb4yssVQZL7vEtErhORK4ALfIzJmDyXkpLCM888Q2xsbPogcW3atLEkYCKClyuCYSJSCngQ5/6BksA//QzKmLy0Zs0aEhMT+frrr+nQoQM33nhjqEMyJk9le0Wgqm+r6kFVXaOqzVX1SuD3PIjNGN9NnjyZevXqsWnTJl5++WUWLVpE2bJlQx2WMXkq2A1lUcCtOGMMvauqa0SkA/AIUAy4Im9CNCb3qSoiQmxsLJ06dWLcuHGUKVMm1GEZExLBqoZeAMoBXwPjRWQnkAAMVNU38iC2XGW9Rw3AkSNHGDJkCFFRUYwcOZKmTZvStGnTUIdlTEgFSwQJQB1VTRWRGOBXoIqq7sub0Pwh1n80Yn3yySd069aNn3/+md69e6dfFRgT6YK1EZxQ1VQAVT0GbAr3JGAi08GDB7n33nvTh4f+6KOPmDBhgiUBY1zBrghqishq97UAVdxlAVRV6/genTG5YNeuXcyZM4eHHnqIJ598kuLFi4c6JGPylWCJIMdzDohIO5xJbaKA6ao6IovtbgFeBa5S1eU5/V5j9uzZw/z58+nbty81a9Zk8+bN1hhsTBaCDTqXo4Hm3F5HE4DWwHbgGxFZpKrrMmxXAmf6y69y8n3GgNMbaN68edx///0cOnSItm3bUr16dUsCxgThafL6s1Qf2Kiqm1T1BDAfuCGT7Z4CRgLHfIzFRIBt27bRsWNHunTpQtWqVVmxYoUNEmeMB34mgsuAbQHL29116USkHlBOVd8JtiMR6SEiy0Vk+Z49e84uGht+tEBLTk6mWbNmfPzxx4wdO5Zly5ZRq1atUIdlTFjwMsQEIlIMKK+qG3Lri0WkEPAMcHd226rqVGAqQEJCQo5KdOsoUrBs3ryZcuXKER0dzZQpU6hcuTKVK1cOdVjGhJVsrwhEpCOwEnjXXa4rIos87HsHzg1pacq669KUAOKBT0RkM/BXYJGIJHiK3ES05ORkRo8eTWxsLBMnTgSgVatWlgSMOQteqoaewKnvPwCgqitx5ibIzjdANRGpJCJFgNuA9ATijl9UWlUrqmpF4Evgeus1ZLKzevVqGjRowMMPP0zbtm255ZZbQh2SMWHN0zDUqnoww7psq2dUNRnoAywB1gMLVHWtiAwVkevPPFRjYOLEiVx55ZVs2bKF//73vyxcuJBLL7001GEZE9a8tBGsFZE7gCgRqQbcD3zuZeequhhYnGHdkCy2beZlnyYypQ0HER8fz2233cbYsWMpXbp0qMMypkDwckXQF2e+4uPAy8BBwnA+AuszFJ7+/PNPHnjgAQYMGABAkyZNmD17tiUBY3KRl0RQU1UHq+pV7uNRd+yhsGSdhsLHhx9+SO3atRk3bhzHjx9HrQuwMb7wkgjGiMh6EXlKROJ9j8hEvAMHDtCtWzdatWpFdHQ0S5cuZfz48TZInDE+8TJDWXOgObAHmCIi34vIo75HZiLWb7/9xvz58/nXv/7FqlWraNy4cahDMqZA83Rnsar+qqrjgZ449xRk2uBrzNn67bffePbZZwGoUaMGmzdvZsSIERQrVizEkRlT8Hm5oSxWRJ4Qke9xJq//HOfmMGNyTFWZM2cOcXFxDBgwgJ9++gnAGoONyUNerghm4NxM1lZVm6nqJFXd7W9YJhJs3bqV6667jq5du1KjRg1WrlxJtWrVQh2WMREn2/sIVLVBXgTiN+twkr+kDRK3e/duxo8fT+/evYmKigp1WMZEpCwTgYgsUNVb3SqhwGI0rGcos54nobVp0yYqVKhAdHQ006ZNo0qVKlSsWDHUYRkT0YJVDfVznzsAHQMeacvGeJacnMzIkSOJi4tjwoQJALRs2dKSgDH5QJaJQFV3uS97q+qWwAfQO2/CMwXBypUrufrqqxk4cCDXXnstnTp1CnVIxpgAXhqLW2eyrn1uB2IKpueff56rrrqKHTt28Oqrr/L6669zySWXhDosY0yAYG0EvXDO/CuLyOqAt0oAy/wOzIS3tEHi6tSpQ5cuXXjmmWe44IILQh2WMSYTwXoNvQz8D/gPMDBg/R+q+ruvUZmwdfjwYQYPHkzhwoUZPXo0TZo0oUmTJqEOyxgTRLCqIVXVzcB9wB8BD0Qk7E7tbMAy/7333nvEx8fz3HPPkZSUZL+5MWEiuyuCDsC3ON1HA/tdKhCWcwJa59Hct3//fvr378/MmTOpUaMGS5cu5Zprrgl1WMYYj7JMBKrawX32Mi2liWC7d+/m1VdfZdCgQQwZMoSYmJhQh2SMOQNexhpqJCLnuK/vFJFnRKS8/6GZ/OzXX39l7NixwMlB4oYPH25JwJgw5KX76CTgiIhcDjwI/AzM9jUqk2+pKrNmzSIuLo5BgwalDxJ34YUXhjgyY8zZ8pIIktVp9bsBeF5VJ+B0ITURZvPmzbRr1467776buLg4GyTOmALCy+T1f4jIIKAr0FhECgGF/Q0r91n/lZxJTk6mefPm7N27lwkTJtCzZ08KFfI0nYUxJp/zkgg6A3cA/1DVX932gaf9Dcs/Nubcmdm4cSOVKlUiOjqaGTNmULlyZSpUqBDqsIwxucjLVJW/AnOBUiLSATimqi/5HpkJqaSkJIYPH06tWrXSB4lr3ry5JQFjCiAvvYZuBb4GOgG3Al+JyN/8DsyEznfffUf9+vUZPHgwN9xwA507dw51SMYYH3mpGhoMXJU2K5mIlAE+AF71MzATGuPHj6d///6UKVOG119/nZtuuinUIRljfOalta9Qhqkp93n8nAkjacNBXHHFFfz9739n3bp1lgSMiRBergjeFZElwDx3uTOw2L+QTF76448/GDRoEEWLFmXMmDE0btyYxo0bhzosY0we8tJY/DAwBajjPqaq6r/8Diy32fhnp3v33XeJj49n4sSJqKoNEmdMhAo2H0E1YDRQBfgeeEhVd+RVYH4RG3aOffv20b9/f1566SViY2NZtmwZDRo0CHVYxpgQCXZFMAN4G7gFZwTS5/IkIuO7ffv2sXDhQh577DFWrFhhScCYCBcsEZRQ1WmqukFVRwMVz3TnItJORDaIyEYRGZjJ+/1FZJ2IrBaRD0XEOqn7ZNeuXYwePRpVpXr16mzZsoWhQ4dStGjRUIdmjAmxYIkgRkSuEJF6IlIPKJZhOSgRiQIm4MxvHAfcLiJxGTZbASSoah2c7qijzu4wTFZUlRkzZhAbG8tjjz3Gxo0bATj//PNDHJkxJr8I1mtoF/BMwPKvAcsKtMhm3/WBjaq6CUBE5uMMXLcubQNV/Thg+y+BO72Fbbz45Zdf6NGjBx988AFNmjRh2rRpNkicMeY0wSamaZ7DfV8GbAtY3g5cHWT7RJw5kk8jIj2AHgDly5/dVAiR1h8mOTmZFi1asG/fPiZNmkSPHj1skDhjTKa83EfgOxG5E0gAmmb2vqpOBaYCJCQk5KxML+Cdhn766ScqV65MdHQ0L774IlWqVKFcuXKhDssYk4/5eYq4Awgsgcq6604hIq1whrG4XlWP+xhPgZaUlMSwYcOIj4/n+eefB6BZs2aWBIwx2fLziuAboJqIVMJJALfhDGedTkSuwLlZrV2GYSzMGVi+fDmJiYmsXr2a2267jdtvvz3UIRljwoiX0UfFnat4iLtcXkTqZ/c5VU0G+gBLgPXAAlVdKyJDReR6d7OngXOBV0RkpYgsOusjiVDPPvssV199NXv37uXNN99k3rx5XHTRRaEOyxgTRrxcEUwEUnF6CQ0F/gBeA67K7oOqupgM4xKp6pCA163OJFhzkqoiIiQkJJCYmMioUaM477zzQh2WMSYMeUkEV6tqPRFZAaCq+0WkiM9xmSwcOnSIf/3rX8TExDB27FgaNWpEo0aNQh2WMSaMeWksTnJvDlNIn48g1deofFAQBlRbvHgxtWrVYurUqURHRxeIYzLGhJ6XRDAeWAhcJCL/Bj4DhvsalY/Ccc7ivXv3cuedd3LddddRqlQpPv/8c55++mkkHA/GGJPvZFs1pKpzReRboCVOL/wbVXW975GZdPv37+ett97i8ccf55FHHqFIEauZM8bknmwTgYiUB44AbwWuU9WtfgYW6Xbs2MHcuXN5+OGHqVatGlu2bLHGYGOML7w0Fr+D0z4gQAxQCdgA1PIxroilqkyfPp2HHnqIpKQkbr75ZqpWrWpJwBjjGy8zlNVW1TruczWcweS+8D+0yPPzzz/TsmVLevToQb169Vi9ejVVq1YNdVjGmALujO8sVtXvRCTY4HHmLCQnJ9OyZUt+//13pkyZQrdu3WyQOGNMnvDSRtA/YLEQUA/Y6VtEEWbDhg1UqVKF6OhoZs2aRZUqVShbtmyowzLGRBAvp5wlAh5FcdoMbvAzKD/llw6XJ06c4Mknn6R27dpMmDABgKZNm1oSMMbkuaBXBO6NZCVU9aE8iicifP311yQmJrJmzRruuOMOunTpEuqQjDERLMsrAhGJVtUUwMYvyEXjxo2jQYMG6fcGzJ07l9KlS4c6LGNMBAt2RfA1TntA2qigrwB/pr2pqq/7HFuBkjZIXP369enevTsjR46kVKlSoQ7LGGM89RqKAfbhjD6adj+BApYIPDh48CADBgygWLFijBs3joYNG9KwYcNQh2WMMemCNRZf5PYYWgN87z6vdZ/X5EFsuSoU47O99dZbxMXFMX36dIoWLWqDxBlj8qVgVwRROJPGZNbRJmxLtLwYqG3Pnj3069ePefPmUbt2bd544w2uuirb6RuMMSYkgiWCXao6NM8iKUAOHjzI4sWLefLJJxk4cKANEmeMydeCJYL80uU+LGzbto05c+YwcOBAqlatypYtW6wx2BgTFoK1EbTMsyjCWGpqKpMnT6ZWrVoMGzaMn3/+GcCSgDEmbGSZCFT197wMJBz99NNPtGjRgl69elG/fn2+//57GyTOGBN2znjQOeNITk6mdevWHDhwgBdeeIF77rnHZgwzxoSliEkEmksdndavX0+1atWIjo5m9uzZVKlShUsvvTRX9m1MJEhKSmL79u0cO3Ys1KEUSDExMZQtW5bChQt7/kzEJII0Z3vOfvz4cYYPH87w4cN5+umn+ec//0njxo1zNTZjIsH27dspUaIEFStWtKvoXKaq7Nu3j+3bt1OpUiXPn4u4RHA2vvzySxITE1m3bh1du3ala9euoQ7JmLB17NgxSwI+EREuvPBC9uzZc0afs5lPsjFmzBgaNmzIH3/8weLFi3nppZe48MILQx2WMWHNkoB/zua3tUSQhdTUVAAaNGhAz549WbNmDe3btw9xVMYYk/ssEWRw4MABEhMT6devHwANGzZk4sSJlCxZMsSRGWNyS1RUFHXr1iU+Pp6OHTty4MCB9PfWrl1LixYtqFGjBtWqVeOpp546ZZyw//3vfyQkJBAXF8cVV1zBgw8+GIIjyF2WCAK88cYbxMXFMWvWLEqUKGGDxBlTQBUrVoyVK1eyZs0aLrjggvRZAo8ePcr111/PwIED2bBhA6tWreLzzz9n4sSJAKxZs4Y+ffowZ84c1q1bx/Lly3P93qHk5ORc3Z8XEdNYHKxM3717N3369OGVV16hbt26vP3229SrVy/vgjMmQj351lrW7TyUq/uMu7Qkj3es5Xn7Bg0asHr1agBefvllGjVqRJs2bQAoXrw4zz//PM2aNeO+++5j1KhRDB48mJo1awLOlUWvXr1O2+fhw4fp27cvy5cvR0R4/PHHueWWWzj33HM5fPgwAK+++ipvv/02M2fO5O677yYmJoYVK1bQqFEjXn/9dVauXMl5550HQLVq1fjss88oVKgQPXv2ZOvWrYAz0VWjRjmfOyxiEkGazNpRDh06xPvvv8+///1vHn744TPqf2uMCV8pKSl8+OGHJCYmAk610JVXXnnKNlWqVOHw4cMcOnSINWvWeKoKeuqppyhVqhTff/89APv378/2M9u3b+fzzz8nKiqKlJQUFi5cyD333MNXX31FhQoVuPjii7njjjt44IEHuOaaa9i6dStt27Zl/fr1Z3Hkp4q4RJBm69atzJ49m0ceeYSqVauydetWSpQoEeqwjIkoZ3LmnpuOHj1K3bp12bFjB7GxsbRu3TpX9//BBx8wf/789OXzzz8/28906tSJqKgoADp37szQoUO55557mD9/Pp07d07f77p169I/c+jQIQ4fPsy5556bo3h9bSMQkXYiskFENorIwEzeLyoi/3Xf/0pEKvoZDzi9gSZOnEitWrUYPnx4+iBxlgSMiRxpbQRbtmxBVdPbCOLi4vj2229P2XbTpk2ce+65lCxZklq1ap32/pkI7NqZ8c7qc845J/11gwYN2LhxI3v27OGNN97g5ptvBpzy68svv2TlypWsXLmSHTt25DgJgI+JQESigAlAeyAOuF1E4jJslgjsV9WqwFhgpF/xACTt20671i257777aNCgAWvXrrVB4oyJYMWLF2f8+PGMGTOG5ORkunTpwmeffcYHH3wAOFcO999/PwMGDADg4YcfZvjw4fz444/AydGHM2rdunV6coGTVUMXX3wx69evJzU1lYULF2YZl4hw00030b9/f2JjY9PvXWrTpg3PPfdc+nYrV67M2Q/g8vOKoD6wUVU3qeoJYD5wQ4ZtbgBmua9fBVqKT3eapCQn89uCIaxds4YXX3yRJUuWULFiRT++yhgTRq644grq1KnDvHnzKFasGG+++SbDhg2jRo0a1K5dm6uuuoo+ffoAUKdOHcaNG8ftt99ObGws8fHxbNq06bR9Pvroo+zfv5/4+Hguv/xyPv74YwBGjBhBhw4daNiwIZdccknQuDp37sycOXPSq4UAxo8fz/Lly6lTpw5xcXGZJqGzIX51kRSRvwHtVLWbu9wVuFpV+wRss8bdZru7/LO7zd4M++oB9AAoX778lVu2bDnjeN5f9xuT5r/NmG5tqVS+7NkeljEmh9avX09sbGyowyjQMvuNReRbVU3IbPuwaCxW1anAVICEhISzylyt4y6m9dDEXI3LGGMKAj+rhnYA5QKWy7rrMt1GRKKBUsA+H2MyxhiTgZ+J4BugmohUEpEiwG3AogzbLALucl//DfhI7XZeYwo8+2/un7P5bX1LBKqaDPQBlgDrgQWqulZEhorI9e5mLwAXishGoD9wWhdTY0zBEhMTw759+ywZ+CBtPoKYmJgz+pxvjcV+SUhI0OXLl4c6DGPMWbIZyvyV1QxlYd9YbIwpOAoXLnxGs2cZ/9noo8YYE+EsERhjTISzRGCMMREu7BqLRWQPcOa3FjtKA3uz3apgsWOODHbMkSEnx1xBVctk9kbYJYKcEJHlWbWaF1R2zJHBjjky+HXMVjVkjDERzhKBMcZEuEhLBFNDHUAI2DFHBjvmyODLMUdUG4ExxpjTRdoVgTHGmAwsERhjTIQrkIlARNqJyAYR2Sgip41oKiJFReS/7vtfiUjFEISZqzwcc38RWSciq0XkQxGpEIo4c1N2xxyw3S0ioiIS9l0NvRyziNzq/q3XisjLeR1jbvPwb7u8iHwsIivcf9/XhiLO3CIiM0RktzuDY2bvi4iMd3+P1SJSL8dfqqoF6gFEAT8DlYEiwCogLsM2vYHJ7uvbgP+GOu48OObmQHH3da9IOGZ3uxLAUuBLICHUcefB37kasAI4312+KNRx58ExTwV6ua/jgM2hjjuHx9wEqAesyeL9a4H/AQL8Ffgqp99ZEK8I6gMbVXWTqp4A5gM3ZNjmBmCW+/pVoKWISB7GmNuyPWZV/VhVj7iLX+LMGBfOvPydAZ4CRgIFYcxjL8fcHZigqvsBVHV3HseY27wcswIl3delgJ15GF+uU9WlwO9BNrkBeEkdXwLnicglOfnOgpgILgO2BSxvd9dluo06E+gcBC7Mk+j84eWYAyXinFGEs2yP2b1kLqeq7+RlYD7y8neuDlQXkWUi8qWItMuz6Pzh5ZifAO4Uke3AYqBv3oQWMmf6/z1bNh9BhBGRO4EEoGmoY/GTiBQCngHuDnEoeS0ap3qoGc5V31IRqa2qB0IZlM9uB2aq6hgRaQDMFpF4VU0NdWDhoiBeEewAygUsl3XXZbqNiETjXE7uy5Po/OHlmBGRVsBg4HpVPZ5Hsfklu2MuAcQDn4jIZpy61EVh3mDs5e+8HVikqkmq+gvwI05iCFdejjkRWACgql8AMTiDsxVUnv6/n4mCmAi+AaqJSCURKYLTGLwowzaLgLvc138DPlK3FSZMZXvMInIFMAUnCYR7vTFkc8yqelBVS6tqRVWtiNMucr2qhvM8p17+bb+BczWAiJTGqSralIcx5jYvx7wVaAkgIrE4iWBPnkaZtxYBf3d7D/0VOKiqu3KywwJXNaSqySLSB1iC0+NghqquFZGhwHJVXQS8gHP5uBGnUea20EWccx6P+WngXOAVt118q6peH7Kgc8jjMRcoHo95CdBGRNYBKcDDqhq2V7sej/lBYJqIPIDTcHx3OJ/Yicg8nGRe2m33eBwoDKCqk3HaQa4FNgJHgHty/J1h/HsZY4zJBQWxasgYY8wZsERgjDERzhKBMcZEOEsExhgT4SwRGGNMhLNEEGFEJEVEVgY8KgbZ9nAufN9MEfnF/a7v3Ds/z3Qf00Ukzn39SIb3Ps9pjO5+0n6XNSLyloicl832dfNqlEu3v/hHIlLSXQ46OqWH/XVwR+pc5Y5Sem8uxzvUvXkREWnsjoK6UkQuE5FX3fWefj8R6SMi/8jN+MzprPtohBGRw6p6bm5vG2QfM4G3VfVVEWkDjFbVOjnYX45jym6/IjIL+FFV/x1k+7txRjPtk8txRLvjXwWuuw5opaoPuMtNgMM4A4/Fn+H+CwNbgPqqul1EigIVVXVD7hzBad83GfhMVedkWH83Hn4/ESkOLFPVK/yIzzjsiiDCici54sxP8J2IfC8ip43gKSKXiMjSgDPmxu76NiLyhfvZV0QkuwJ6KVDV/Wx/d19rROSf7rpzROQd90x1jYh0dtd/IiIJIjICKObGMdd977D7PN8tMNNinikifxORKBF5WkS+EWfsdi9nv1/gDuIlIvXdY1whIp+LSA1x7nAdCnR2Y+nsxj5DRL52t83sdxQ3ljXub512fM1E5FMRWQSsyySeLsCbaQseRqcMpgTOjaT73H0dT0sC7m82WUSWi8iPItLBXZ/lbygi/3KPZZX79wn87bsBtwJPichcEanoHntmv99PIlLG/XwhccbaL+OOmLtZROqf5fEaL/JqjG175I8Hzt2mK93HQpxCoaT7XmmcuxXTrhQPu88PAoPd11E4hUlpnIL9HHf9v4AhmXzfTOBv7utOwFfAlcD3wDk4dzuvBa4AbgGmBXy2lPv8Ce5cAmkxBWyTFuNNwCz3dRGc0RmLAT2AR931RYHlQKVM4jwccHyvAO3c5ZJAtPu6FfCa+/pu4PmAzw8H7nRfn4czxs85Gb7jFuB99zsuxhka4RKcu0j/zCwu93NbgBIZ1lUki/HqPfwbmA7sBubhJJlCAX+rd3FOEKvhjFsUk9VvCLQHPufkPBcXZPI3D3ydHnMmv9/jwD/d123Sfmd3eTDwYKj/7xTkR4EbYsJk66iq1k1bcKsKhrvVDak4Z8IXA78GfOYbYIa77RuqulJEmuJMArJMnCEriuCcSWfmaRF5FGf8l0SccWEWquqfbgyvA41xCqExIjISpzrp0zM4rv8Bz7pVHe2Apap61K2OqiMif3O3K4VTyP2S4fPFRGSle/zrcQrstO1niUg1nOELCmfx/W2A60XkIXc5Bijv7ivNNcA8VU0BfhOR/wOuAg4BX6szSFxmLlDVP4Ifvneq2k1EauMktoeA1pwcpXWBOqN2/iQim4Ca7rFl9hu2Al5Ud54LVT3bqxSAGThXPeOAfwAvBry3243D+MQSgekClAGuVNUkcUbqjAncQFWXuoniOmCmiDwD7AfeV9XbPXzHw6r6atqCiLTMbCNV/VGcOQSuBYaJyIeqOtTLQajqMRH5BGgLdMaZwAScWZz6quqSbHZxVFXrunXSS4D7gPE4E9t8rKo3idOw/kkWnxfgFj37uvY/g7yXLCKF1OOwyiISBXzrLi5S1SEZt1HV74HvRWQ2TlK8O+2tjJuSxW8oIm29xOOFqm4Tkd9EpAXOZDRdAt6OAY7m1neZ01kbgSkF7HaTQHPgtLmMxZnf+DdVnYZTrVAPZzTPRiKSVud/johU9/idnwI3ikhxETkHp1rnUxG5FDiiTsPi0+73ZJTkXplk5r84A3ClXV2AU6j3SvuMiFR3vzNT7tnt/cCDcnKI8rQhfu8O2PQPnCqyNEuAvuJeHokz2mtmx93ZrXMvgzMl4ddZxRJgA85UjZ6oaoqq1nUfpyQBcdqEmgWsqotT9ZSmk1tHX8X9zg1k/Ru+D9zjJk9E5AKvMXL67wfOv605wCvuVVOa6sBZ9ZAy3lgiMHOBBBH5Hvg78EMm2zQDVonICpyz7WdVdQ9OwThPRFbjVAt5unxX1e9w6o6/xmkzmK6qK4DawNduFc3jwLBMPj4VWC1uY3EG7+FMuPOBOtMaglO4rAO+E6e75RSyuRJ2Y1mNM+HJKOA/7rEHfu5jIC6tsRPnyqGwG9tadzmjhe5+VwEfAQNU9ddMtsvoHdyhpSF9dMovgBoisl1EEj3sI/3jwABxJoNfCTzJqQluK87f5X9AT1U9Rha/oaq+izMk8nJ3Xw/hXcbfD3df53JqtRBAI05W1RkfWPdRY/I5ceajfUlVW/v8PTNxu/r6+T1Bvj8BGKuqjQPWXQH0V9WuoYgpUtgVgTH5nDqTjkwT94aygkhEBgKvAYMyvFUaeCzvI4osdkVgjDERzq4IjDEmwlkiMMaYCGeJwBhjIpwlAmOMiXCWCIwxJsL9P+A1hOVfpRT1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "fpr,tpr,threshold = roc_curve(df['Label'], df['prob'])\n",
    "roc_auc =auc(fpr, tpr)\n",
    "\n",
    "plt.figure(frameon=False)\n",
    "plt.plot(fpr, tpr, label='ROC curve')\n",
    "plt.plot([0,1],[0,1], 'k--')\n",
    "plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
    "plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "\n",
    "fig.savefig(\"ROC Curve.png\", bbox_inches='tight', pad_inches=0, transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Convert model to ONNX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.decoder.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.weight', 'predictions.LayerNorm.bias', 'predictions.bias', 'predictions.dense.bias', 'predictions.dense.weight']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_52286/3353613314.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Random'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path_to_model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    605\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    880\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(data_type, size, key, location)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstorage_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/lib/python3.8/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "if config['Model']['convert_to_onnx']:\n",
    "    sequences = {'AGCTAAGCTAAGCTA':'AAGACTGACAGCTAA'}\n",
    "    sequences=pd.DataFrame(sequences.items(), columns=['Sequence1', 'Sequence2'])\n",
    "    dataset = CustomDataset(\n",
    "        data = sequences,\n",
    "        maxlen = config['Model']['max_len'],\n",
    "        with_labels = False #sulyginti su class cusotmedatasets\n",
    "        )\n",
    "    \n",
    "    model = Model(bert_model)\n",
    "    \n",
    "    model.load_state_dict(torch.load(config['Random']['path_to_model']))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    #defining model inputs, which are ids, kmask and toke type ids (it comes from Model Class)\n",
    "    input_ids= dataset[0][0].unsqueeze(0).cuda()\n",
    "    attn_masks = dataset[0][0].unsqueeze(0).cuda()\n",
    "    token_type_ids = dataset[0][0].unsqueeze(0).cuda()\n",
    "        \n",
    "    torch.onnx.export(\n",
    "        model, #.module if paralized\n",
    "        (input_ids, attn_masks, token_type_ids),\n",
    "        \"model.onnx\",\n",
    "        input_names=[\"input_ids\", \"attn_masks\", \"token_type_ids\"], \n",
    "        output_names=[\"output\"],\n",
    "        #which inputs have dynamical axes\n",
    "        verbose=True,\n",
    "        dynamic_axes={\n",
    "            \"input_ids\": {0: \"batch_size\"},\n",
    "            \"attn_masks\": {0: \"batch_size\"},\n",
    "            \"token_type_ids\": {0: \"batch_size\"},\n",
    "            \"output\": {0: \"batch_size\"},\n",
    "        },\n",
    "        opset_version=10,\n",
    "        )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
