####
https://www.analyticsvidhya.com/blog/2017/06/transfer-learning-the-art-of-fine-tuning-a-pre-trained-model/

Neural networks are a different breed of models compared to the supervised machine learning algorithms. Why do I say so? There are multiple reasons for that, but the most prominent is the cost of running algorithms on the hardware.

On the other hand, access to GPUs is not that cheap.

Now, that may change in future. But for now, it means that we have to be smarter about the way we use our resources in solving Deep Learning problems. Especially so, when we try to solve complex real life problems on areas like image and voice recognition.

Thankfully, there is something called “Transfer Learning” which enables us to use pre-trained models from other people by making small changes.

[transfer learning image su smegenimis :)]

A neural network is trained on a data. This network gains knowledge from this data, which is compiled as “weights” of the network. These weights can be extracted and then transferred to any other neural network. Instead of training the other neural network from scratch, we “transfer” the learned features.





















####
https://medium.com/@ailabs/transformers-fine-tuning-the-fine-tuned-model-526fe622992b

In these experiments, we show that fine-tuning the already fine-tuned model for specific tasks can lead to significant gain, even if the original pre-trained model is huge. 

